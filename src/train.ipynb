{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "source": [
    "## Library Import"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam, AdamW\n",
    "from torchvision.models import resnet18, resnet34, resnet50\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import Subset\n",
    "import torch.utils.data as torchdata\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional\n",
    "import logging\n",
    "from numpy.random import beta\n",
    "from pathlib import Path\n",
    "\n",
    "from conformer import ConformerConvModule\n",
    "from conformer import ConformerBlock\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Configuration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# use GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2813, 128])\n"
     ]
    }
   ],
   "source": [
    "# sample data\n",
    "sample = torch.from_numpy(np.load('melspec.npy'))\n",
    "print(sample.shape)\n",
    "# channel = sample.unsqueeze(0)\n",
    "# batch = channel.unsqueeze(0)\n",
    "# print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    SEED = 42\n",
    "    INPUT = Path(\"../input/rfcx-species-audio-detection/train\")\n",
    "    TRAIN_AUDIO_ROOT = Path(\"../input/rfcx-species-audio-detection/train_mel\")\n",
    "    TEST_AUDIO_ROOT = Path(\"../input/rfcx-species-audio-detection/test_mel\")\n",
    "    TRAIN_TP = Path(\"../input/rfcx-species-audio-detection/train_tp.csv\")\n",
    "    DIM = sample.shape[1]\n",
    "    SEQ_LEN = sample.shape[0]\n",
    "    CLASS_NUM = 23\n",
    "    KERNEL_SIZE = 3\n",
    "    POOL_SIZE = 2\n",
    "    POOL_STRIDE = 2\n",
    "    NUM_BIRDS = 24\n",
    "    N_FOLDS = 5\n",
    "    BTCH_NUM = 50\n",
    "    EPOCH_NUM = 100\n",
    "    lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)  # type: ignore\n",
    "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
    "set_seed(config.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all audio to 2d\n",
    "# run audio_transformer"
   ]
  },
  {
   "source": [
    "## Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spec Augment\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any other augment here...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Modeling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conformer\n",
    "# https://arxiv.org/abs/2005.08100\n",
    "class RainforestTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RainforestTransformer, self).__init__()         \n",
    "\n",
    "        self.conv = nn.Conv2d(1, 1, config.KERNEL_SIZE)\n",
    "        self.linear = nn.Linear(int(\n",
    "                                    (\n",
    "                                        ((config.DIM - config.KERNEL_SIZE + 1) - config.POOL_SIZE) / config.POOL_STRIDE\n",
    "                                    ) + 1\n",
    "                                ), config.DIM)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.conformerblock = ConformerBlock(\n",
    "            dim = config.DIM,\n",
    "            dim_head = 64,\n",
    "            heads = 8,\n",
    "            ff_mult = 4,\n",
    "            conv_expansion_factor = 2,\n",
    "            conv_kernel_size = 31,\n",
    "            attn_dropout = 0.,\n",
    "            ff_dropout = 0.,\n",
    "            conv_dropout = 0.\n",
    "        )\n",
    "        self.decoder = nn.Linear(1 * int((((config.SEQ_LEN - config.KERNEL_SIZE + 1) -  config.POOL_SIZE) / config.POOL_STRIDE) + 1) * config.DIM, config.CLASS_NUM)\n",
    "\n",
    "        # devided by stride\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.conv(x))\n",
    "        h = F.max_pool2d(h, config.POOL_SIZE, stride=config.POOL_STRIDE)\n",
    "        h = self.linear(h)\n",
    "        h = h.transpose(0, 1)[0] # transpose batch and channel to delet channel dimension\n",
    "        h = self.conformerblock(h)\n",
    "        h = h.view(-1, 1 * int((((config.SEQ_LEN - config.KERNEL_SIZE + 1) -  config.POOL_SIZE) / config.POOL_STRIDE) + 1) * config.DIM)\n",
    "        out = self.decoder(h)\n",
    "        return out"
   ]
  },
  {
   "source": [
    "## Metric"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LRAP. Instance-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = (scores.sum(-1) / labels.sum(-1)).mean()\n",
    "    return score.item()\n",
    "\n",
    "# label-level average\n",
    "# Assume float preds [BxC], labels [BxC] of 0 or 1\n",
    "def LWLRAP(preds, labels):\n",
    "    # Ranks of the predictions\n",
    "    ranked_classes = torch.argsort(preds, dim=-1, descending=True)\n",
    "    # i, j corresponds to rank of prediction in row i\n",
    "    class_ranks = torch.zeros_like(ranked_classes)\n",
    "    for i in range(ranked_classes.size(0)):\n",
    "        for j in range(ranked_classes.size(1)):\n",
    "            class_ranks[i, ranked_classes[i][j]] = j + 1\n",
    "    # Mask out to only use the ranks of relevant GT labels\n",
    "    ground_truth_ranks = class_ranks * labels + (1e6) * (1 - labels)\n",
    "    # All the GT ranks are in front now\n",
    "    sorted_ground_truth_ranks, _ = torch.sort(ground_truth_ranks, dim=-1, descending=False)\n",
    "    # Number of GT labels per instance\n",
    "    num_labels = labels.sum(-1)\n",
    "    pos_matrix = torch.tensor(np.array([i+1 for i in range(labels.size(-1))])).unsqueeze(0)\n",
    "    score_matrix = pos_matrix / sorted_ground_truth_ranks\n",
    "    score_mask_matrix, _ = torch.sort(labels, dim=-1, descending=True)\n",
    "    scores = score_matrix * score_mask_matrix\n",
    "    score = scores.sum() / labels.sum()\n",
    "    return score.item()"
   ]
  },
  {
   "source": [
    "## Transforms"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.RandomCrop((128, 313), pad_if_needed=True, padding_mode=\"constant\"),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "valid_transform = transforms.Compose([\n",
    "    # transforms.CenterCrop((128, 313)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "label_transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "source": [
    "## Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    recording_id  species_id  songtype_id    t_min   f_min   t_max    f_max  \\\n",
       "538    77299bde7          21            1  42.3787  3750.0  43.472  5531.25   \n",
       "\n",
       "     0  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17  18  19  20  \\\n",
       "538  0  0  0  0  0  0  0  0  1  0   0   0   0   0   0   0   0   0   0   0   0   \n",
       "\n",
       "     21  22  23  \n",
       "538   1   0   0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recording_id</th>\n      <th>species_id</th>\n      <th>songtype_id</th>\n      <th>t_min</th>\n      <th>f_min</th>\n      <th>t_max</th>\n      <th>f_max</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>538</th>\n      <td>77299bde7</td>\n      <td>21</td>\n      <td>1</td>\n      <td>42.3787</td>\n      <td>3750.0</td>\n      <td>43.472</td>\n      <td>5531.25</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 225
    }
   ],
   "source": [
    "# Data load\n",
    "df_train_tp = pd.read_csv(config.TRAIN_TP)\n",
    "\n",
    "# add column\n",
    "for col in range(24):\n",
    "    df_train_tp[col] = 0\n",
    "\n",
    "# bit\n",
    "for index, row in df_train_tp.iterrows():\n",
    "    specId = row[\"species_id\"]\n",
    "    for col in range(24):\n",
    "        if int(specId) == col:\n",
    "            df_train_tp.iloc[index, df_train_tp.columns.get_loc(col)] = 1\n",
    "\n",
    "# grouping\n",
    "df_train_tp = df_train_tp.groupby(\"recording_id\", as_index=False).max()\n",
    "\n",
    "# check\n",
    "df_train_tp[df_train_tp[\"recording_id\"] == \"77299bde7\"].head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "003bec244\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "record_ids = []\n",
    "labels = []\n",
    "for index, row in df_train_tp.iterrows():\n",
    "    record_ids.append(row.values[0])\n",
    "    labels.append(row.values[7:31])\n",
    "\n",
    "print(record_ids[0])\n",
    "print(labels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RainforestDatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, transform = None, train = True):\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "        # data load\n",
    "        self.labelset = labels\n",
    "        self.dataset = []\n",
    "        for rid in record_ids:\n",
    "            # read npy\n",
    "            melspec = np.load(os.path.join(config.TRAIN_AUDIO_ROOT, rid + \".npy\"))\n",
    "            melspec = torch.from_numpy(melspec)\n",
    "            melspec = melspec.unsqueeze(0) # add channel for first convolution\n",
    "            self.dataset.append(melspec)\n",
    "\n",
    "        self.datanum = len(self.dataset)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get data\n",
    "        out_label = self.labelset[idx]\n",
    "        out_data = self.dataset[idx]\n",
    "        \n",
    "        # transform label\n",
    "        out_data = self.transform(out_data)\n",
    "        out_label = label_transform(out_label)\n",
    "\n",
    "        return out_data, out_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skf\n",
    "# skf = StratifiedKFold(n_splits=config.N_FOLDS, shuffle=True, random_state=config.SEED)\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=config.N_FOLDS, test_size=0.2, random_state=config.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform\n",
    "train_datasets = RainforestDatasets(transform=train_transform)\n",
    "valid_datasets = RainforestDatasets(transform=valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(902,)\n(230,)\n(905,)\n(227,)\n(906,)\n(226,)\n(906,)\n(226,)\n(903,)\n(229,)\n"
     ]
    }
   ],
   "source": [
    "for kfoldidx, (train_index, test_index) in enumerate(msss.split(labels, labels)):\n",
    "    X = Subset(train_datasets, train_index)\n",
    "    train_dataloader = DataLoader(X, 20, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x2d9af310370>"
      ]
     },
     "metadata": {},
     "execution_count": 305
    }
   ],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "optimizer = Adam(params=model.parameters(), lr=config.lr, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}